from nltk import bigrams, trigrams
from collections import Counter, defaultdict
from nltk.corpus.reader.plaintext import PlaintextCorpusReader
stutter = PlaintextCorpusReader("/Users/LindsayHippe/Documents/Stutter/preprocessed", ".*")


# create placeholder for model
model = defaultdict(lambda: defaultdict(lambda: 0))

# count frequency of co-occurance  
for sentence in stutter.sents():
    for w1, w2 in bigrams(sentence, pad_right=True, pad_left=True):
        model[(w1)][w2] += 1
 
# transform the counts to probabilities
for w1 in model:
    total_count = float(sum(model[w1].values()))
    for w2 in model[w1]:
        model[w1][w2] /= total_count

import random

#starting words
text = input('> ').split()
sentence_finished = False
 
while not sentence_finished:
  # select a random probability threshold  
  r = random.random()
  accumulator = .0

  for word in model[(text[-1])].keys():
      accumulator += model[(text[-1])][word]
      # select words that are above the probability threshold
      if accumulator >= r:
          text.append(word)
          break

  if text[-1] == None:
      sentence_finished = True
 
print (' '.join([t for t in text if t]))